Parsed 396875 operator-reward pairs from /cma-log/output_for_ana.txt
OperatorPolicyNet(
  (op_embedding): Embedding(15, 10)
  (net): Sequential(
    (0): Linear(in_features=170, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
)

============================================================
Training started...
============================================================
[Epoch 0] loss = 5.592054
  Policy metric (logp*reward): 0.8625, MSE=69.6439, Correlation=0.0699
[Epoch 1] loss = 5.532378
[Epoch 2] loss = 5.502041
  Policy metric (logp*reward): 0.9808, MSE=67.0567, Correlation=0.0760
[Epoch 3] loss = 5.460459
[Epoch 4] loss = 5.406128
  Policy metric (logp*reward): 1.2245, MSE=66.7929, Correlation=0.0711
[Epoch 5] loss = 5.341374
[Epoch 6] loss = 5.274941
  Policy metric (logp*reward): 1.2632, MSE=73.1514, Correlation=0.0530
[Epoch 7] loss = 5.206750
[Epoch 8] loss = 5.145263
  Policy metric (logp*reward): 1.3101, MSE=77.0711, Correlation=0.0442
[Epoch 9] loss = 5.081715
[Epoch 10] loss = 5.026091
  Policy metric (logp*reward): 1.8252, MSE=88.4828, Correlation=0.0482
[Epoch 11] loss = 4.972405
[Epoch 12] loss = 4.915559
  Policy metric (logp*reward): 2.3499, MSE=102.6799, Correlation=0.0525
[Epoch 13] loss = 4.866227
[Epoch 14] loss = 4.822963
  Policy metric (logp*reward): 2.5509, MSE=116.3894, Correlation=0.0513
[Epoch 15] loss = 4.772341
[Epoch 16] loss = 4.739661
  Policy metric (logp*reward): 2.0803, MSE=131.2470, Correlation=0.0370
[Epoch 17] loss = 4.700639
[Epoch 18] loss = 4.656082
  Policy metric (logp*reward): 2.5688, MSE=139.5618, Correlation=0.0425
[Epoch 19] loss = 4.619735
[Epoch 20] loss = 4.592940
  Policy metric (logp*reward): 2.2514, MSE=153.6407, Correlation=0.0345
[Epoch 21] loss = 4.562472
[Epoch 22] loss = 4.530827
  Policy metric (logp*reward): 3.0298, MSE=164.4738, Correlation=0.0441
[Epoch 23] loss = 4.508676
[Epoch 24] loss = 4.478372
  Policy metric (logp*reward): 2.8365, MSE=175.2982, Correlation=0.0395
[Epoch 25] loss = 4.453188
[Epoch 26] loss = 4.432483
  Policy metric (logp*reward): 3.1596, MSE=185.1231, Correlation=0.0417
[Epoch 27] loss = 4.403843
[Epoch 28] loss = 4.386641
  Policy metric (logp*reward): 3.2305, MSE=196.4785, Correlation=0.0413
[Epoch 29] loss = 4.359147
[Epoch 30] loss = 4.344073
  Policy metric (logp*reward): 2.9371, MSE=211.6868, Correlation=0.0357
[Epoch 31] loss = 4.321361
[Epoch 32] loss = 4.304100
  Policy metric (logp*reward): 3.8897, MSE=231.5619, Correlation=0.0440
[Epoch 33] loss = 4.293489
[Epoch 34] loss = 4.271591
  Policy metric (logp*reward): 3.9764, MSE=247.3502, Correlation=0.0435
[Epoch 35] loss = 4.250772
[Epoch 36] loss = 4.233823
  Policy metric (logp*reward): 3.7732, MSE=262.4188, Correlation=0.0391
[Epoch 37] loss = 4.223584
[Epoch 38] loss = 4.199159
  Policy metric (logp*reward): 3.6879, MSE=279.1182, Correlation=0.0367
  Policy metric (logp*reward): 3.6414, MSE=280.8872, Correlation=0.0366

============================================================
Training completed. Generating results...
============================================================

------------------------------------------------------------
Operator Embeddings Analysis
------------------------------------------------------------

Embedding shape: (15, 10) (16 operators × 10 dims)

Embedding statistics per operator:
Op   Mean       Std        Min        Max        Norm      
------------------------------------------------------------
0    0.0334     0.4869     -0.7438    0.8169     1.5432    
1    -0.1975    0.4370     -0.8323    0.8233     1.5165    
2    -0.0995    0.7109     -1.2999    0.9128     2.2701    
3    -0.1097    0.4406     -1.0672    0.5664     1.4358    
4    -0.0180    0.4442     -0.7831    0.7780     1.4057    
5    0.2375     0.5099     -0.4372    1.2249     1.7788    
6    -0.3727    0.6897     -1.7252    0.6692     2.4791    
7    -0.2344    0.6551     -1.3802    1.0022     2.2001    
8    -0.2329    0.6644     -1.3938    0.9587     2.2265    
9    0.0739     0.6822     -0.9540    1.7336     2.1700    
10   -0.0044    0.3288     -0.6927    0.3837     1.0397    
11   -0.0812    0.6167     -1.2912    1.1607     1.9669    
12   -0.0677    0.4604     -0.8259    0.4929     1.4716    
13   -0.0877    0.6830     -0.8382    1.6580     2.1777    
14   -0.0261    0.6841     -1.0535    0.9411     2.1648    

------------------------------------------------------------
Operator Embedding Vectors:
------------------------------------------------------------
Operator  0: [  0.8169  -0.0788   0.5252  -0.0793  -0.7438   0.3013  -0.5064  -0.2651   0.6229  -0.2592]
Operator  1: [ -0.3193  -0.0962  -0.2735   0.0039  -0.2866  -0.8323  -0.5460  -0.5862   0.1383   0.8233]
Operator  2: [ -0.0093   0.0167   0.4248   0.6260  -0.0110  -1.1601  -1.2999  -0.7904   0.9128   0.2951]
Operator  3: [ -0.1338   0.5664  -0.0808   0.4197   0.0347  -1.0672  -0.1136  -0.5588  -0.2575   0.0939]
Operator  4: [  0.7780  -0.7831  -0.2866   0.2475   0.5834  -0.1475  -0.1770  -0.4669   0.0391   0.0333]
Operator  5: [ -0.3380   0.2499  -0.4372   0.8641  -0.2534   0.4815   0.2633  -0.0980   0.4175   1.2249]
Operator  6: [ -0.7637   0.3381  -1.1744   0.6692   0.2426  -0.6485  -1.7252  -0.3299  -0.1512  -0.1845]
Operator  7: [ -0.2897   0.4613  -0.7774  -0.4685  -0.5807   1.0022  -0.5817  -1.3802   0.3570  -0.0864]
Operator  8: [ -0.1741  -0.0082   0.0363   0.9587   0.4372   0.1298  -0.5608  -1.3938  -0.9123  -0.8422]
Operator  9: [ -0.2390   1.7336   0.2235   0.4834   0.3561  -0.2820  -0.9540  -0.4833   0.0113  -0.1109]
Operator 10: [ -0.5120  -0.0278  -0.0436   0.1111   0.3837   0.0128   0.2103   0.2469   0.2674  -0.6927]
Operator 11: [ -0.4044  -0.5145  -0.3010   1.1607   0.0247  -0.1242   0.3911  -1.2912   0.3840  -0.1375]
Operator 12: [  0.0809   0.3620   0.2847   0.3746  -0.5677  -0.3464   0.4929  -0.6519  -0.8259   0.1194]
Operator 13: [ -0.2418  -0.4931   0.6148   1.6580  -0.5811  -0.2966  -0.3148  -0.2720  -0.8382  -0.1118]
Operator 14: [  0.4994   0.5548  -0.8468   0.6766  -0.0475  -0.8700   0.9411  -0.3682   0.2528  -1.0535]

Operator Embedding Similarity Matrix (cosine similarity):
          0     1     2     3     4     5     6     7     8     9    10    11    12    13    14
Op  0: 1.000-0.056 0.338-0.251 0.128-0.155-0.204 0.293-0.053 0.013-0.346-0.058-0.065 0.034-0.093
Op  1:-0.056 1.000 0.697 0.607 0.124 0.318 0.523 0.209 0.036 0.212-0.466 0.283 0.184 0.151-0.113
Op  2: 0.338 0.697 1.000 0.570 0.258 0.070 0.532 0.076 0.240 0.477-0.166 0.349-0.023 0.297 0.013
Op  3:-0.251 0.607 0.570 1.000 0.015 0.037 0.498-0.059 0.404 0.602-0.129 0.344 0.573 0.348 0.470
Op  4: 0.128 0.124 0.258 0.015 1.000-0.113 0.094-0.067 0.326-0.278-0.191 0.376-0.145 0.093 0.146
Op  5:-0.155 0.318 0.070 0.037-0.113 1.000 0.079 0.205-0.152 0.071-0.279 0.371 0.090 0.151-0.100
Op  6:-0.204 0.523 0.532 0.498 0.094 0.079 1.000 0.295 0.448 0.543 0.091 0.220-0.128 0.229 0.086
Op  7: 0.293 0.209 0.076-0.059-0.067 0.205 0.295 1.000 0.294 0.254-0.175 0.262 0.011-0.230-0.052
Op  8:-0.053 0.036 0.240 0.404 0.326-0.152 0.448 0.294 1.000 0.395 0.104 0.575 0.410 0.573 0.215
Op  9: 0.013 0.212 0.477 0.602-0.278 0.071 0.543 0.254 0.395 1.000 0.005 0.003 0.179 0.096 0.130
Op 10:-0.346-0.466-0.166-0.129-0.191-0.279 0.091-0.175 0.104 0.005 1.000 0.163-0.396-0.094 0.318
Op 11:-0.058 0.283 0.349 0.344 0.376 0.371 0.220 0.262 0.575 0.003 0.163 1.000 0.297 0.475 0.410
Op 12:-0.065 0.184-0.023 0.573-0.145 0.090-0.128 0.011 0.410 0.179-0.396 0.297 1.000 0.540 0.299
Op 13: 0.034 0.151 0.297 0.348 0.093 0.151 0.229-0.230 0.573 0.096-0.094 0.475 0.540 1.000 0.043
Op 14:-0.093-0.113 0.013 0.470 0.146-0.100 0.086-0.052 0.215 0.130 0.318 0.410 0.299 0.043 1.000

Most similar operator pairs (top 5):
  1. Op  1 <-> Op  2: 0.6968
  2. Op  1 <-> Op  3: 0.6069
  3. Op  3 <-> Op  9: 0.6025
  4. Op  8 <-> Op 11: 0.5748
  5. Op  8 <-> Op 13: 0.5733

Embedding change (L2 norm from initial):
Op   Change    
--------------------
0    2.1476    
1    1.4399    
2    1.8991    
3    0.9081    
4    1.4341    
5    1.4337    
6    1.7730    
7    1.5849    
8    1.1679    
9    1.1870    
10   1.4466    
11   1.1368    
12   1.2138    
13   2.2967    
14   1.3149    

------------------------------------------------------------
Prediction Analysis
------------------------------------------------------------

Overall prediction metrics:
  Note: We optimize policy gradient loss (-log_prob * reward), not MSE
  MSE (reference):     280.887238
  MAE (reference):    13.268838
  Correlation:         0.0366
  Policy metric (proxy): 3.6414 (higher is better)

Per-operator prediction statistics:
Op   Count    Avg Pred     Avg True     MSE         
------------------------------------------------------------
0    20766    10.2113      2.2510       247.773376  
1    14389    9.7833       2.1635       250.608276  
2    14060    9.8382       2.2648       247.047409  
3    21660    11.0106      2.7329       264.940338  
4    17060    10.4770      2.9581       258.295837  
5    12777    9.4715       2.2904       237.486298  
6    16202    9.8364       1.8527       246.214798  
7    12739    9.2507       2.4688       235.369476  
8    12484    9.7465       2.3571       246.389343  
9    18121    10.2230      2.4892       254.782623  
10   23837    10.6550      2.1096       259.203430  
11   20220    10.3914      1.8889       258.681244  
12   24384    10.6941      2.4899       262.785461  
13   17221    9.1036       1.0849       232.144897  
14   150955   12.9245      3.6127       328.427765  

Sample predictions (first 10):
Idx    Op   Pred Score   True Reward  Diff        
------------------------------------------------------------
0      14   1.3192       14.5000      -13.1808    
1      14   15.7839      0.0315       15.7524     
2      14   17.0624      33.7500      -16.6876    
3      14   18.4943      0.0625       18.4318     
4      5    5.8764       0.7500       5.1264      
5      14   8.5215       0.0635       8.4581      
6      0    4.5138       0.0315       4.4823      
7      14   7.7828       0.0317       7.7511      
8      9    9.4498       3.0000       6.4498      
9      4    22.6786      0.0315       22.6471     

============================================================
Operator Priority Analysis - Which operators to prioritize?
============================================================

------------------------------------------------------------
Operators ranked by AVERAGE REWARD (best performers first):
------------------------------------------------------------
Rank   Op   Avg Reward   Usage      Count      Std       
------------------------------------------------------------
1      14   3.6127       38.04     % 150955     9.7771    
2      4    2.9581       4.30      % 17060      7.6785    
3      3    2.7329       5.46      % 21660      7.4387    
4      12   2.4899       6.14      % 24384      7.1062    
5      9    2.4892       4.57      % 18121      7.0589    
6      7    2.4688       3.21      % 12739      7.1321    
7      8    2.3571       3.15      % 12484      7.0436    
8      5    2.2904       3.22      % 12777      6.7311    
9      2    2.2648       3.54      % 14060      6.7543    
10     0    2.2510       5.23      % 20766      6.7399    
11     1    2.1635       3.63      % 14389      6.5764    
12     10   2.1096       6.01      % 23837      6.5367    
13     11   1.8889       5.09      % 20220      6.1744    
14     6    1.8527       4.08      % 16202      6.1345    
15     13   1.0849       4.34      % 17221      4.4434    

------------------------------------------------------------
Operators ranked by TOTAL REWARD CONTRIBUTION:
------------------------------------------------------------
Rank   Op   Total Reward   Avg Reward   Usage     
------------------------------------------------------------
1      14   545355.69      3.6127       38.04     %
2      12   60712.83       2.4899       6.14      %
3      3    59194.03       2.7329       5.46      %
4      4    50465.57       2.9581       4.30      %
5      10   50286.76       2.1096       6.01      %
6      0    46744.23       2.2510       5.23      %
7      9    45105.89       2.4892       4.57      %
8      11   38193.69       1.8889       5.09      %
9      2    31843.66       2.2648       3.54      %
10     7    31450.37       2.4688       3.21      %

------------------------------------------------------------
Operators ranked by USAGE FREQUENCY:
------------------------------------------------------------
Rank   Op   Usage      Count      Avg Reward  
------------------------------------------------------------
1      14   38.04     % 150955     3.6127      
2      12   6.14      % 24384      2.4899      
3      10   6.01      % 23837      2.1096      
4      3    5.46      % 21660      2.7329      
5      0    5.23      % 20766      2.2510      
6      11   5.09      % 20220      1.8889      
7      9    4.57      % 18121      2.4892      
8      13   4.34      % 17221      1.0849      
9      4    4.30      % 17060      2.9581      
10     6    4.08      % 16202      1.8527      

------------------------------------------------------------
RECOMMENDATION: Top operators to prioritize
------------------------------------------------------------

Top 5 operators to prioritize (based on composite score):
Composite score = avg_reward × (1 + reliability) × usage_rate
Rank   Op   Composite    Avg Reward   Usage      Count     
----------------------------------------------------------------------
1      14   138.82       3.6127       38.04     % 150955    
2      12   15.51        2.4899       6.14      % 24384     
3      3    15.12        2.7329       5.46      % 21660     
4      4    12.88        2.9581       4.30      % 17060     
5      10   12.86        2.1096       6.01      % 23837     

Bottom 3 operators (consider reducing usage):
Rank   Op   Avg Reward   Usage      Count     
--------------------------------------------------
1      11   1.8889       5.09      % 20220     
2      6    1.8527       4.08      % 16202     
3      13   1.0849       4.34      % 17221     

------------------------------------------------------------
SUMMARY:
------------------------------------------------------------
✓ Best average reward: Operators 14, 4, 3
✓ Highest total contribution: Operators 14, 12, 3
✓ Recommended priority: Operators 14, 12, 3

------------------------------------------------------------
Saving results...
------------------------------------------------------------
✓ Saved operator embeddings to: ./out/operator_embeddings.npy
✓ Saved similarity matrix to: ./out/operator_similarity_matrix.npy
✓ Saved prediction results to: ./out/prediction_results.npz

============================================================
Model Recommendation Demo
============================================================

Sample recommendations (using trained model):
--------------------------------------------------------------------------------

Sample 1 (context index 40602):
  Recommended operator: 14 (probability: 0.4933, score: -12.1649)
  Top 3 operators:
    1. Operator 14: prob=0.4933, score=-12.1649
    2. Operator 11: prob=0.1104, score=-13.6618
    3. Operator  0: prob=0.0751, score=-14.0474

Sample 2 (context index 80075):
  Recommended operator: 9 (probability: 0.2603, score: -4.3275)
  Top 3 operators:
    1. Operator  9: prob=0.2603, score=-4.3275
    2. Operator 14: prob=0.1218, score=-5.0868
    3. Operator  2: prob=0.1139, score=-5.1539

Sample 3 (context index 342333):
  Recommended operator: 14 (probability: 0.3675, score: -3.0482)
  Top 3 operators:
    1. Operator 14: prob=0.3675, score=-3.0482
    2. Operator 11: prob=0.1543, score=-3.9157
    3. Operator  8: prob=0.1120, score=-4.2362

Sample 4 (context index 189040):
  Recommended operator: 14 (probability: 0.3287, score: -0.0317)
  Top 3 operators:
    1. Operator 14: prob=0.3287, score=-0.0317
    2. Operator  0: prob=0.0910, score=-1.3161
    3. Operator  5: prob=0.0870, score=-1.3611

Sample 5 (context index 361795):
  Recommended operator: 14 (probability: 0.2411, score: 15.5164)
  Top 3 operators:
    1. Operator 14: prob=0.2411, score=15.5164
    2. Operator  9: prob=0.2233, score=15.4398
    3. Operator  5: prob=0.0910, score=14.5421

------------------------------------------------------------
Overall Model Recommendation Statistics:
------------------------------------------------------------

Model recommendation frequency (based on 1000 random contexts):
Op   Recommendation Rate  Count     
----------------------------------------
0    6.20                % 62        
1    0.80                % 8         
2    2.70                % 27        
3    1.30                % 13        
4    3.00                % 30        
5    0.40                % 4         
6    0.60                % 6         
7    0.40                % 4         
8    0.60                % 6         
9    3.10                % 31        
10   2.10                % 21        
11   0.50                % 5         
12   2.80                % 28        
13   0.50                % 5         
14   75.00               % 750       

Comparison with actual best operators (by avg reward):
Op   Model Rec Rate     Actual Avg Reward  Match?    
-------------------------------------------------------
0    6.20              % 2.2510             ✓         
1    0.80              % 2.1635             ✗         
2    2.70              % 2.2648             ✗         
3    1.30              % 2.7329             ✗         
4    3.00              % 2.9581             ✗         
5    0.40              % 2.2904             ✗         
6    0.60              % 1.8527             ✗         
7    0.40              % 2.4688             ✗         
8    0.60              % 2.3571             ✗         
9    3.10              % 2.4892             ✗         
10   2.10              % 2.1096             ✗         
11   0.50              % 1.8889             ✗         
12   2.80              % 2.4899             ✗         
13   0.50              % 1.0849             ✗         
14   75.00             % 3.6127             ✓         

============================================================
All results saved successfully!
============================================================
