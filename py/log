Parsed 10168 operator-reward pairs from /cma-log/output_for_ana.txt
OperatorPolicyNet(
  (op_embedding): Embedding(15, 10)
  (net): Sequential(
    (0): Linear(in_features=20, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
)

============================================================
Training started...
============================================================
[Epoch 0] loss = 0.724012
  Policy metric (logp*reward): -0.0002, MSE=0.4195, Correlation=-0.0028
[Epoch 1] loss = 0.720635
[Epoch 2] loss = 0.718051
  Policy metric (logp*reward): 0.0100, MSE=0.5143, Correlation=0.0879
[Epoch 3] loss = 0.715683
[Epoch 4] loss = 0.711440
  Policy metric (logp*reward): 0.0021, MSE=0.3302, Correlation=0.0172
[Epoch 5] loss = 0.705997
[Epoch 6] loss = 0.700614
  Policy metric (logp*reward): 0.0226, MSE=0.5112, Correlation=0.0987
[Epoch 7] loss = 0.694080
[Epoch 8] loss = 0.685669
  Policy metric (logp*reward): 0.0478, MSE=0.6256, Correlation=0.1457
[Epoch 9] loss = 0.675233
[Epoch 10] loss = 0.666577
  Policy metric (logp*reward): 0.0670, MSE=0.8374, Correlation=0.1557
[Epoch 11] loss = 0.654278
[Epoch 12] loss = 0.643899
  Policy metric (logp*reward): 0.1270, MSE=1.2287, Correlation=0.2094
[Epoch 13] loss = 0.631005
[Epoch 14] loss = 0.621460
  Policy metric (logp*reward): 0.1638, MSE=1.8448, Correlation=0.2066
[Epoch 15] loss = 0.610803
[Epoch 16] loss = 0.597378
  Policy metric (logp*reward): 0.1759, MSE=2.4983, Correlation=0.1905
[Epoch 17] loss = 0.586317
[Epoch 18] loss = 0.577009
  Policy metric (logp*reward): 0.2146, MSE=3.0847, Correlation=0.2234
[Epoch 19] loss = 0.566497
[Epoch 20] loss = 0.555099
  Policy metric (logp*reward): 0.1849, MSE=4.0440, Correlation=0.1850
[Epoch 21] loss = 0.542543
[Epoch 22] loss = 0.533554
  Policy metric (logp*reward): 0.2944, MSE=5.3285, Correlation=0.2333
[Epoch 23] loss = 0.524334
[Epoch 24] loss = 0.517276
  Policy metric (logp*reward): 0.2794, MSE=6.2722, Correlation=0.1885
[Epoch 25] loss = 0.509647
[Epoch 26] loss = 0.499546
  Policy metric (logp*reward): 0.2800, MSE=7.6455, Correlation=0.2233
[Epoch 27] loss = 0.490974
[Epoch 28] loss = 0.485291
  Policy metric (logp*reward): 0.2493, MSE=8.9547, Correlation=0.1606
[Epoch 29] loss = 0.477128
[Epoch 30] loss = 0.468197
  Policy metric (logp*reward): 0.3771, MSE=10.9244, Correlation=0.2044
[Epoch 31] loss = 0.460836
[Epoch 32] loss = 0.455105
  Policy metric (logp*reward): 0.4478, MSE=12.2159, Correlation=0.2250
[Epoch 33] loss = 0.449627
[Epoch 34] loss = 0.443371
  Policy metric (logp*reward): 0.4010, MSE=14.7498, Correlation=0.1979
[Epoch 35] loss = 0.435752
[Epoch 36] loss = 0.428277
  Policy metric (logp*reward): 0.3706, MSE=16.9977, Correlation=0.1967
[Epoch 37] loss = 0.425088
[Epoch 38] loss = 0.419993
  Policy metric (logp*reward): 0.4520, MSE=17.0849, Correlation=0.2013
[Epoch 39] loss = 0.413483
  Policy metric (logp*reward): 0.4492, MSE=17.8857, Correlation=0.1973

============================================================
Training completed. Generating results...
============================================================

------------------------------------------------------------
Operator Embeddings Analysis
------------------------------------------------------------

Embedding shape: (15, 10) (16 operators × 10 dims)

Embedding statistics per operator:
Op   Mean       Std        Min        Max        Norm      
------------------------------------------------------------
0    0.0615     1.1326     -1.6013    2.7428     3.5868    
1    -0.2293    0.9219     -1.7633    1.2522     3.0042    
2    0.1747     1.0270     -0.8760    2.2112     3.2944    
3    0.2733     1.1908     -1.6626    2.4026     3.8636    
4    -0.7364    1.1218     -2.3366    1.2069     4.2434    
5    0.1081     0.8693     -0.9862    1.5738     2.7702    
6    -0.2785    1.0539     -2.3489    1.2630     3.4472    
7    0.0715     1.1337     -1.3246    1.8231     3.5921    
8    -0.0153    0.7080     -0.9772    1.5549     2.2393    
9    -0.3665    1.0681     -2.5170    1.4121     3.5710    
10   0.4355     1.3541     -1.6822    3.4265     4.4980    
11   -0.1120    1.1355     -1.6384    2.3282     3.6083    
12   0.8180     1.1543     -0.3319    3.6853     4.4738    
13   -0.2372    0.8567     -1.4201    1.5041     2.8112    
14   -0.2066    1.4137     -1.8130    2.7648     4.5180    

------------------------------------------------------------
Operator Embedding Vectors:
------------------------------------------------------------
Operator  0: [ -0.9511   0.1182  -1.6013  -0.2300  -0.2768  -0.4200  -0.4049   0.9728   0.6656   2.7428]
Operator  1: [ -0.3923   0.5717  -0.5697  -0.4974  -1.7633   1.2522   0.3410  -1.4642  -0.5959   0.8245]
Operator  2: [ -0.8760   2.2112   0.8877  -0.7472  -0.5703  -0.1147  -0.3641   1.7601  -0.5236   0.0837]
Operator  3: [  0.3717   1.1238  -0.4813   0.3077  -0.9317  -1.6626   2.4026   1.9192   0.0181  -0.3345]
Operator  4: [ -0.4317   1.2069  -2.0229   1.1420  -1.6892  -0.9812  -0.7615  -2.3366  -0.7741  -0.7159]
Operator  5: [ -0.0284  -0.9501  -0.9862  -0.7398   0.3991   1.3174   0.7985   0.1611   1.5738  -0.4645]
Operator  6: [ -0.0396  -0.2140  -2.3489   0.3073  -1.5436   1.2630  -0.0745   0.6696   0.4547  -1.2590]
Operator  7: [  1.6410   0.7897  -0.6195  -0.1950   1.1850  -1.3246  -0.9354   1.8231  -1.2973  -0.3524]
Operator  8: [ -0.8111   1.5549   0.0722   0.1778   0.2032  -0.5826  -0.4333   0.0277   0.6149  -0.9772]
Operator  9: [  0.2588  -1.2152  -0.2944  -0.5069  -1.0852  -2.5170   0.7885  -0.8040   1.4121   0.2982]
Operator 10: [  3.4265   1.2929  -1.6822  -0.7922   1.2682  -0.4215   1.0291   0.2389   0.4770  -0.4822]
Operator 11: [ -1.0221  -1.6384   0.8108   0.4025  -1.2597   0.5786   0.1099  -0.4957   2.3282  -0.9337]
Operator 12: [  1.1563   1.1405  -0.1008   0.7052   0.4425  -0.3319   1.7182  -0.1535  -0.0818   3.6853]
Operator 13: [ -1.1815  -0.1040  -1.4201  -0.7275  -0.9084  -0.6621   1.5041   0.3834   0.3560   0.3879]
Operator 14: [  0.7330   0.2087   0.7771  -1.6663   2.7648  -1.8130  -0.6767   0.6089  -1.8051  -1.1971]

Operator Embedding Similarity Matrix (cosine similarity):
          0     1     2     3     4     5     6     7     8     9    10    11    12    13    14
Op  0: 1.000 0.161 0.152 0.103-0.002 0.061 0.091 0.009-0.135 0.173-0.099-0.158 0.515 0.510-0.318
Op  1: 0.161 1.000 0.002-0.181 0.488 0.007 0.296-0.556-0.204-0.071-0.200 0.033 0.194 0.285-0.587
Op  2: 0.152 0.002 1.000 0.368-0.144-0.400-0.102 0.303 0.520-0.366-0.133-0.325 0.009 0.071 0.171
Op  3: 0.103-0.181 0.368 1.000-0.022-0.092 0.138 0.301 0.184 0.304 0.340-0.187 0.273 0.560-0.002
Op  4:-0.002 0.488-0.144-0.022 1.000-0.325 0.360-0.113 0.316 0.179-0.027-0.079-0.109 0.169-0.265
Op  5: 0.061 0.007-0.400-0.092-0.325 1.000 0.491-0.366-0.204 0.065 0.217 0.486-0.185 0.318-0.301
Op  6: 0.091 0.296-0.102 0.138 0.360 0.491 1.000-0.097 0.012-0.085 0.110 0.256-0.379 0.368-0.502
Op  7: 0.009-0.556 0.303 0.301-0.113-0.366-0.097 1.000 0.103-0.183 0.552-0.734 0.038-0.248 0.702
Op  8:-0.135-0.204 0.520 0.184 0.316-0.204 0.012 0.103 1.000-0.094-0.020 0.013-0.316-0.006 0.146
Op  9: 0.173-0.071-0.366 0.304 0.179 0.065-0.085-0.183-0.094 1.000 0.065 0.364 0.088 0.474-0.112
Op 10:-0.099-0.200-0.133 0.340-0.027 0.217 0.110 0.552-0.020 0.065 1.000-0.468 0.281-0.037 0.307
Op 11:-0.158 0.033-0.325-0.187-0.079 0.486 0.256-0.734 0.013 0.364-0.468 1.000-0.431 0.112-0.560
Op 12: 0.515 0.194 0.009 0.273-0.109-0.185-0.379 0.038-0.316 0.088 0.281-0.431 1.000 0.150-0.191
Op 13: 0.510 0.285 0.071 0.560 0.169 0.318 0.368-0.248-0.006 0.474-0.037 0.112 0.150 1.000-0.313
Op 14:-0.318-0.587 0.171-0.002-0.265-0.301-0.502 0.702 0.146-0.112 0.307-0.560-0.191-0.313 1.000

Most similar operator pairs (top 5):
  1. Op  7 <-> Op 14: 0.7022
  2. Op  3 <-> Op 13: 0.5595
  3. Op  7 <-> Op 10: 0.5524
  4. Op  2 <-> Op  8: 0.5196
  5. Op  0 <-> Op 12: 0.5147

Embedding change (L2 norm from initial):
Op   Change    
--------------------
0    0.2980    
1    0.4849    
2    0.3698    
3    0.5612    
4    0.4145    
5    0.3287    
6    0.3955    
7    0.4827    
8    0.4202    
9    0.3438    
10   0.3718    
11   0.3913    
12   0.3792    
13   0.3157    
14   0.4337    

------------------------------------------------------------
Prediction Analysis
------------------------------------------------------------

Overall prediction metrics:
  Note: We optimize policy gradient loss (-log_prob * reward), not MSE
  MSE (reference):     17.885687
  MAE (reference):    3.363977
  Correlation:         0.1973
  Policy metric (proxy): 0.4492 (higher is better)

Per-operator prediction statistics:
Op   Count    Avg Pred     Avg True     MSE         
------------------------------------------------------------
0    671      -1.2996      0.3164       18.838749   
1    722      -1.7497      0.2466       17.517895   
2    646      -1.7990      0.2654       17.081938   
3    633      -1.8019      0.2689       17.707350   
4    674      -1.6179      0.2596       18.035387   
5    730      -1.4180      0.2603       16.599674   
6    663      -1.6550      0.2634       17.734888   
7    652      -1.8249      0.2528       17.904768   
8    699      -1.4643      0.2516       17.819538   
9    708      -1.4337      0.2328       16.746721   
10   625      -1.8553      0.2682       18.681847   
11   672      -1.6581      0.2731       18.512840   
12   698      -1.8359      0.2285       17.563942   
13   693      -1.4031      0.2885       17.890095   
14   682      -1.8288      0.3288       19.848572   

Sample predictions (first 10):
Idx    Op   Pred Score   True Reward  Diff        
------------------------------------------------------------
0      7    11.2622      2.5000       8.7622      
1      13   -1.5496      0.1562       -1.7059     
2      10   -5.9047      0.0781       -5.9828     
3      14   -7.5531      0.0781       -7.6312     
4      0    11.3369      0.4688       10.8681     
5      2    8.7660       1.8750       6.8910      
6      9    0.7801       0.4688       0.3114      
7      0    -0.6031      0.3125       -0.9156     
8      12   -3.0638      0.0156       -3.0794     
9      1    -1.7254      0.0156       -1.7410     

============================================================
Operator Priority Analysis - Which operators to prioritize?
============================================================

------------------------------------------------------------
Operators ranked by AVERAGE REWARD (best performers first):
------------------------------------------------------------
Rank   Op   Avg Reward   Usage      Count      Std       
------------------------------------------------------------
1      14   0.3288       6.71      % 682        0.7666    
2      0    0.3164       6.60      % 671        0.7610    
3      13   0.2885       6.82      % 693        0.6341    
4      11   0.2731       6.61      % 672        0.6358    
5      3    0.2689       6.23      % 633        0.5501    
6      10   0.2682       6.15      % 625        0.5447    
7      2    0.2654       6.35      % 646        0.6030    
8      6    0.2634       6.52      % 663        0.6941    
9      5    0.2603       7.18      % 730        0.5334    
10     4    0.2596       6.63      % 674        0.4995    
11     7    0.2528       6.41      % 652        0.5385    
12     8    0.2516       6.87      % 699        0.5334    
13     1    0.2466       7.10      % 722        0.5621    
14     9    0.2328       6.96      % 708        0.4630    
15     12   0.2285       6.86      % 698        0.4445    

------------------------------------------------------------
Operators ranked by TOTAL REWARD CONTRIBUTION:
------------------------------------------------------------
Rank   Op   Total Reward   Avg Reward   Usage     
------------------------------------------------------------
1      14   224.23         0.3288       6.71      %
2      0    212.27         0.3164       6.60      %
3      13   199.95         0.2885       6.82      %
4      5    190.01         0.2603       7.18      %
5      11   183.55         0.2731       6.61      %
6      1    178.08         0.2466       7.10      %
7      8    175.84         0.2516       6.87      %
8      4    174.95         0.2596       6.63      %
9      6    174.61         0.2634       6.52      %
10     2    171.48         0.2654       6.35      %

------------------------------------------------------------
Operators ranked by USAGE FREQUENCY:
------------------------------------------------------------
Rank   Op   Usage      Count      Avg Reward  
------------------------------------------------------------
1      5    7.18      % 730        0.2603      
2      1    7.10      % 722        0.2466      
3      9    6.96      % 708        0.2328      
4      8    6.87      % 699        0.2516      
5      12   6.86      % 698        0.2285      
6      13   6.82      % 693        0.2885      
7      14   6.71      % 682        0.3288      
8      4    6.63      % 674        0.2596      
9      11   6.61      % 672        0.2731      
10     0    6.60      % 671        0.3164      

------------------------------------------------------------
RECOMMENDATION: Top operators to prioritize
------------------------------------------------------------

Top 5 operators to prioritize (based on composite score):
Composite score = avg_reward × (1 + reliability) × usage_rate
Rank   Op   Composite    Avg Reward   Usage      Count     
----------------------------------------------------------------------
1      14   2.49         0.3288       6.71      % 682       
2      0    2.36         0.3164       6.60      % 671       
3      13   2.28         0.2885       6.82      % 693       
4      5    2.22         0.2603       7.18      % 730       
5      11   2.09         0.2731       6.61      % 672       

Bottom 3 operators (consider reducing usage):
Rank   Op   Avg Reward   Usage      Count     
--------------------------------------------------
1      1    0.2466       7.10      % 722       
2      9    0.2328       6.96      % 708       
3      12   0.2285       6.86      % 698       

------------------------------------------------------------
SUMMARY:
------------------------------------------------------------
✓ Best average reward: Operators 14, 0, 13
✓ Highest total contribution: Operators 14, 0, 13
✓ Recommended priority: Operators 14, 0, 13

------------------------------------------------------------
Saving results...
------------------------------------------------------------
✓ Saved operator embeddings to: ./out/operator_embeddings.npy
✓ Saved similarity matrix to: ./out/operator_similarity_matrix.npy
✓ Saved prediction results to: ./out/prediction_results.npz

============================================================
Model Recommendation Demo
============================================================

Sample recommendations (using trained model):
--------------------------------------------------------------------------------

Sample 1 (context index 420):
  Recommended operator: 5 (probability: 0.4763, score: -8.0918)
  Top 3 operators:
    1. Operator  5: prob=0.4763, score=-8.0918
    2. Operator  1: prob=0.1245, score=-9.4333
    3. Operator  3: prob=0.1105, score=-9.5526

Sample 2 (context index 5496):
  Recommended operator: 9 (probability: 0.3197, score: -3.3235)
  Top 3 operators:
    1. Operator  9: prob=0.3197, score=-3.3235
    2. Operator 10: prob=0.1216, score=-4.2901
    3. Operator 12: prob=0.1076, score=-4.4126

Sample 3 (context index 9936):
  Recommended operator: 14 (probability: 0.4838, score: -1.4127)
  Top 3 operators:
    1. Operator 14: prob=0.4838, score=-1.4127
    2. Operator  0: prob=0.2587, score=-2.0387
    3. Operator  7: prob=0.1157, score=-2.8435

Sample 4 (context index 5819):
  Recommended operator: 10 (probability: 0.4708, score: 5.1780)
  Top 3 operators:
    1. Operator 10: prob=0.4708, score=5.1780
    2. Operator 14: prob=0.1001, score=3.6296
    3. Operator  3: prob=0.0832, score=3.4445

Sample 5 (context index 6894):
  Recommended operator: 5 (probability: 0.3542, score: -1.4494)
  Top 3 operators:
    1. Operator  5: prob=0.3542, score=-1.4494
    2. Operator 10: prob=0.2360, score=-1.8553
    3. Operator 11: prob=0.0685, score=-3.0928

------------------------------------------------------------
Overall Model Recommendation Statistics:
------------------------------------------------------------

Model recommendation frequency (based on 1000 random contexts):
Op   Recommendation Rate  Count     
----------------------------------------
0    7.40                % 74        
1    5.60                % 56        
2    3.60                % 36        
3    4.50                % 45        
4    2.60                % 26        
5    10.20               % 102       
6    4.50                % 45        
7    5.80                % 58        
8    4.00                % 40        
9    5.30                % 53        
10   15.90               % 159       
11   7.40                % 74        
12   9.90                % 99        
13   5.10                % 51        
14   8.20                % 82        

Comparison with actual best operators (by avg reward):
Op   Model Rec Rate     Actual Avg Reward  Match?    
-------------------------------------------------------
0    7.40              % 0.3164             ✗         
1    5.60              % 0.2466             ✗         
2    3.60              % 0.2654             ✗         
3    4.50              % 0.2689             ✗         
4    2.60              % 0.2596             ✗         
5    10.20             % 0.2603             ✗         
6    4.50              % 0.2634             ✗         
7    5.80              % 0.2528             ✗         
8    4.00              % 0.2516             ✗         
9    5.30              % 0.2328             ✗         
10   15.90             % 0.2682             ✗         
11   7.40              % 0.2731             ✗         
12   9.90              % 0.2285             ✗         
13   5.10              % 0.2885             ✗         
14   8.20              % 0.3288             ✗         

============================================================
All results saved successfully!
============================================================
